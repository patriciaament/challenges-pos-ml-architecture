{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto Final: Classificação de Textos usando Machine Learning\n",
        "<hr>\n",
        "\n",
        "#### Classificação de texto a partir de algoritmos de classificação. <br>"
      ],
      "metadata": {
        "id": "lHX9g6SWrPii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "uWdIyUKKrGSF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 1:\n",
        "Insira os modulos do NLTK para fazer download"
      ],
      "metadata": {
        "id": "BFsbweo-sHyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt'), nltk.download('wordnet'), nltk.download('averaged_perceptron_tagger'), nltk.download('stopwords'), nltk.download('punkt_tab'), nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJwyzZcCsOJ8",
        "outputId": "ccea176b-858f-48e3-905b-79ea055ef4a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True, True, True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 2:\n",
        "A definição de sementes aleatórias pode ser definida pelo seguinte código:"
      ],
      "metadata": {
        "id": "TnIrjk8CsQep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(500)"
      ],
      "metadata": {
        "id": "Mw92sqh7slnl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 3:\n",
        "Qual o tipo de dados da variável Corpus criada?\n"
      ],
      "metadata": {
        "id": "sHdqedeasn1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus = pd.read_csv('corpus.csv',encoding='latin-1')"
      ],
      "metadata": {
        "id": "M018lDrdzjJK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(Corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "qtHkQLKwzufa",
        "outputId": "d5a8e52f-bf08-4b1b-c711-766c543a8981"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 4:\n",
        "Para remover linhas em branco, se houver, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "igH4H_MusvAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus['text'].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "LuLftIDrs0m0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 5:\n",
        "Para passar todo o texto para letras minúsculas, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "00THmACUs1Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus['text'] = [entry.lower() for entry in Corpus['text']]"
      ],
      "metadata": {
        "id": "NTPSFiUss9vn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 6:\n",
        "Para quebrar o corpus em um conjunto de palavras, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "b69ENfTotAPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus['text'] = [word_tokenize(entry) for entry in Corpus['text']]"
      ],
      "metadata": {
        "id": "wDD2djaCstmh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 7:\n",
        "Para fazer o mapa de taggeamento das palavras em Adjetivo, Verbo e Advérbio, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "c7X3DhqStQei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV"
      ],
      "metadata": {
        "id": "aBQxyxPbtUYE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 8:\n",
        "A lematização é o processo de converter uma palavra em sua forma básica, e o wordnet é um grande banco de dados lexical disponível gratuitamente e publicamente para a língua inglesa, com o objetivo de estabelecer relações semânticas estruturadas entre palavras. Ele também oferece recursos de lematização e é um dos primeiros e mais usados ​​lematizadores. Para iniciar o WordNet Lemmatizer, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "TDCysp8-tdVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index,entry in enumerate(Corpus['text']):\n",
        "    Final_words = []\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    for word, tag in pos_tag(entry):\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    Corpus.loc[index,'text_final'] = str(Final_words)"
      ],
      "metadata": {
        "id": "BwmGm5VKtTll"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 9:\n",
        "Para separar o conjunto entre treino e teste, com 70% para treino e 30% para teste, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "VEdRGRvxtpZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['label'],test_size=0.30)"
      ],
      "metadata": {
        "id": "yb-TFyJjtrzl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 10:\n",
        "Label encoder pode ser usado para normalizar rótulos e também para transformar rótulos não numéricos (desde que sejam rashable e comparáveis) em rótulos numéricos. Para iniciar a transformação dos dados categóricos do tipo string no conjunto de dados em valores numéricos que o modelo possa entender, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "GIUm5UYbt0DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "metadata": {
        "id": "HoZgfjwGt3Vx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 11:\n",
        "Ao utilizar o TF-IDF, com o tamanho máximo do vocabulário definido em 5000, devemos utilizar qual trecho de código?"
      ],
      "metadata": {
        "id": "VBVzmoINt5uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(Corpus['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "metadata": {
        "id": "U1a0QnG0t-sA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 12:\n",
        "Considerando os valores de (n_estimators = 10, random_state = 0) e o conjunto de treino e teste como 70/30, o Random Forest teve a sua acurácia prevista na faixa de qual porcentagem?"
      ],
      "metadata": {
        "id": "Uou6FormuIQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificador - Algoritmo - RF\n",
        "clf_rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
        "clf_rf.fit(Train_X_Tfidf, Train_Y)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = clf_rf.predict(Test_X_Tfidf)\n",
        "\n",
        "accuracy = accuracy_score(Test_Y, y_pred)\n",
        "print(\"Accuracy on training set: {:.3f}\".format(round(accuracy,2)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(round(accuracy,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1joA_ez3ZWe",
        "outputId": "6a1365b1-94cd-40c9-b58f-c7aada7eb120"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 0.770\n",
            "Accuracy on test set: 0.770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 13:\n",
        "Considerando os valores de (n_estimators = 100, random_state = 0) e o conjunto de treino e teste como 80/20 em relação ao Random Forest, marque a alternativa CORRETA:"
      ],
      "metadata": {
        "id": "aBcpnm63uivz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refazendo o treinamento com os parametros informados no anunciado\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['label'],test_size=0.20)\n",
        "\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "\n",
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(Corpus['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "\n",
        "clf_rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "clf_rf.fit(Train_X_Tfidf, Train_Y)\n",
        "\n",
        "\n",
        "y_pred = clf_rf.predict(Test_X_Tfidf)\n",
        "\n",
        "accuracy = accuracy_score(Test_Y, y_pred)\n",
        "print(\"Accuracy on training set: {:.3f}\".format(round(accuracy,2)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(round(accuracy,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_QBzd3T5REF",
        "outputId": "8ea446fd-449c-4ba0-cd12-92d653966a02"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 0.830\n",
            "Accuracy on test set: 0.830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O RF possui uma acurácia baixa devido à impossibilidade de ajustar seus parâmetros."
      ],
      "metadata": {
        "id": "Y-aHBeMyusg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pergunta 14:\n",
        "Pensando na perspectiva de melhoria dos modelos de Machine Learning, podemos avaliar o ajuste de hiperparâmetros, considerando as seguintes técnicas:"
      ],
      "metadata": {
        "id": "Jv6oX-SluuGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Search, Grid Search, Cross Validation."
      ],
      "metadata": {
        "id": "XjFFOsymu0SE"
      }
    }
  ]
}